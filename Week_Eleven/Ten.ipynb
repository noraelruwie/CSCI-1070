{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ccd6ce-b1b8-4219-93b8-4a334ef96df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  Viscera_weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell_weight  Rings  \n",
       "0         0.150     15  \n",
       "1         0.070      7  \n",
       "2         0.210      9  \n",
       "3         0.155     10  \n",
       "4         0.055      7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('abalone.csv')\n",
    "abalone = df\n",
    "\n",
    "abalone.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dae0ab-21c5-4a91-99ee-a7550c3e5690",
   "metadata": {},
   "source": [
    "# Q1: What is inductive reasoning? Deductive reasoning? Give an example of each, different from the examples given in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5b5a6-b3c2-43c9-ba45-0fa848a0d3b6",
   "metadata": {},
   "source": [
    "* Inductive reasoning is when you make generalizations based on specific observations. So if someone goes to a college campus and sees lots of students studying in the library they might come to the generalization that all students study in the library\n",
    "* Deductive reasoning is when you make a specific conclusion based off general knowledge. It is a way to come to logical conclusions with minimal information. So if you know that all mammals are warm-blooded, and that a dog is a mammal, then you would use deductive reasoning to come to the conclusion that a dog is warm blooded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9f20a-7b3b-473d-b820-29e3eb76b3d5",
   "metadata": {},
   "source": [
    "# Q2: Preprocess your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d457a7d5-e7cf-4869-8980-d79b7be371a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>2</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>2</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0       2   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       2   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       0   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       2   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       1   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    0   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    2   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    2   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    0   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    2   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def preprocess_data(abalone):\n",
    "    sex_encoder = LabelEncoder()\n",
    "    abalone['Sex'] = sex_encoder.fit_transform(abalone['Sex'])  # Encoding categorical variable 'Sex'\n",
    "    # 1 is infant, 2 is male, 0 is female\n",
    "\n",
    "    X = abalone.drop(columns=['Diameter'])  \n",
    "    y = abalone['Diameter'] \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    numerical_features = ['Length', 'Height', 'Whole_weight', 'Shucked_weight', 'Viscera_weight', 'Shell_weight']\n",
    "\n",
    "    numerical_transformer = StandardScaler()\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features)\n",
    "        ], remainder='passthrough')\n",
    "    \n",
    "    \n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "    return X_train_preprocessed, X_test_preprocessed, y_train, y_test\n",
    "\n",
    "\n",
    "X_train_preprocessed, X_test_preprocessed, y_train, y_test = preprocess_data(abalone)\n",
    "\n",
    "abalone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6df6c7-6ca5-4866-9f78-11ea0d4a8e22",
   "metadata": {},
   "source": [
    "# Q3 Create and Tune a Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e709559-44bf-458e-b10d-98dc4d602c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best Parameters: {'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Mean Squared Error for Abalone Decision Tree: 0.0002880811510598701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "def tune_decision_tree(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'max_depth': [3,5,7,10],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    } \n",
    "\n",
    "    dt_regressor = DecisionTreeRegressor(random_state=42) \n",
    "    grid_search = GridSearchCV(estimator=dt_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train) \n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_) \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "X_train_preprocessed, X_test_preprocessed, y_train, y_test = preprocess_data(abalone) \n",
    "best_decision_tree_model = tune_decision_tree(X_train_preprocessed, y_train) \n",
    "best_decision_tree_model = tune_decision_tree(X_train_preprocessed, y_train) \n",
    "best_decision_tree_model.fit(X_train_preprocessed, y_train) \n",
    "decision_tree_prediction = best_decision_tree_model.predict(X_test_preprocessed) \n",
    "\n",
    "mse_decision_tree = mean_squared_error(y_test, decision_tree_prediction) \n",
    "print(\"Mean Squared Error for Abalone Decision Tree:\", mse_decision_tree) \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b7fff-0da8-4dd2-adba-53ba8d540757",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "* I started by creating a parameter grid that had different values for the max depth, min samples, and min samples leaf. Then I used GridSearchCV to perform cross-validation. Squared Error is the most important part of Decision Tree models as it tells us how well it's doing so I implemented that as well as to keep going until I got a lower squared error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caffcea8-2342-4f19-8a85-cf4f687eebc5",
   "metadata": {},
   "source": [
    "# Q4 Create a Random Forest Model and tune it to the best of your abilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95a4ffd-2cb0-4db1-84d5-5dae67260879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.1.2/libexec/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "80 fits failed out of a total of 160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.1.2/libexec/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.1.2/libexec/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.1.2/libexec/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/homebrew/Cellar/jupyterlab/4.1.2/libexec/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.1.2/libexec/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan -0.0003797  -0.00037547 -0.0003797  -0.00037547\n",
      " -0.0003797  -0.00037547 -0.0003797  -0.00037547         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.00027016 -0.00026776 -0.00026973 -0.00026745 -0.00026969 -0.0002676\n",
      " -0.00026969 -0.0002676 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "Mean Squared Error for Random Forest: 0.00027291787747169027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tune_random_forest(X_train, y_train, param_grid):\n",
    "    rf_regressor = RandomForestRegressor(random_state=42) \n",
    "    grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5, scoring= 'neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train) \n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50,100],\n",
    "    'max_depth': [3, 5],\n",
    "    'min_samples_split': [2,3],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "\n",
    "X_train_preprocessed, X_test_preprocessed, y_train, y_test = preprocess_data(abalone) \n",
    "best_random_forest_model = tune_random_forest(X_train_preprocessed, y_train, param_grid_rf) \n",
    "random_forest_predictions = best_random_forest_model.predict(X_test_preprocessed) \n",
    "\n",
    "mse_random_forest = mean_squared_error(y_test, random_forest_predictions) \n",
    "print(\"Mean Squared Error for Random Forest:\", mse_random_forest) \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db38d5b-447a-4028-9d15-59e18901db51",
   "metadata": {},
   "source": [
    " The thing I spent the most time tuning was the param grid for this model and I'm still not sure if its at the best place possible. Then I used GridSearchCV to find the best combo of hyperparameters. Then, used the mean squared error to ensure the model is working correctly. I still ran into a few errors but I troubleshooted and I cant figure out how to fix them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327e5ed-ff4b-48f1-a456-aa26f2462c7c",
   "metadata": {},
   "source": [
    "# Q5  Create an xgboost model tuned to the best of your abilities. Explain how you tuned it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f1754c6-3c2d-4d6b-b2c9-162a2a9793e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/homebrew/Cellar/jupyterlab/4.1.2/libexec/lib/python3.12/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.12/site-packages (from xgboost) (1.26.3)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/Cellar/jupyterlab/4.1.2/libexec/lib/python3.12/site-packages (from xgboost) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54436d7f-ebf2-4a52-a36a-98a79ab5c6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Mean Squared Error for XGBoost: 0.0002447119408237649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "def tune_xgboost(X_train, y_train):  \n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [1,2],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'gamma': [0, 0.1],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.8]\n",
    "    }\n",
    "    xgb_regressor = XGBRegressor(random_state=42) \n",
    "    grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train) \n",
    "    print(\"Best Parameters:\", grid_search.best_params_) \n",
    "    return grid_search.best_estimator_ \n",
    "\n",
    "X_train_preprocessed, X_test_preprocessed, y_train, y_test = preprocess_data(abalone) \n",
    "best_xgboost_model = tune_xgboost(X_train_preprocessed, y_train) \n",
    "xgboost_predictions = best_xgboost_model.predict(X_test_preprocessed) \n",
    "mse_xgboost = mean_squared_error(y_test, xgboost_predictions) \n",
    "print(\"Mean Squared Error for XGBoost:\", mse_xgboost)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29247a-b5d6-44d9-a518-e2fbb9efcd28",
   "metadata": {},
   "source": [
    "Starting with making the param grid like the other models, again I needed to mess with the dimensions of the param grid so that my model could run faster. Also did cross validation through use of GridSearchCV to find the best combination of hyperparameters. Then I used mean squared error as a way to score how well the model runs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6c42232-4843-4639-85e8-bb36f30d65e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for training data: 0.013397145905904375\n",
      "RMSE for testing data: 0.01564327142332335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "train_predictions = best_xgboost_model.predict(X_train_preprocessed)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))\n",
    "print(\"RMSE for training data:\", train_rmse)\n",
    "\n",
    "test_predictions = best_xgboost_model.predict(X_test_preprocessed)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(\"RMSE for testing data:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eb7b4b-248a-4dae-a36f-64af4d83a935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
